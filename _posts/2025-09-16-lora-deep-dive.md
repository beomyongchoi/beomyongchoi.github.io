# LoRA (Low-Rank Adaptation) 심층 분석

LoRA는 거대 언어 모델(LLM)을 특정 과제에 맞게 효율적으로 파인튜닝하기 위한 **PEFT(Parameter-Efficient Fine-Tuning)** 기법 중 가장 대표적이고 성공적인 방법론.

---

### 1. 문제 제기: 전체 파인튜닝(Full Fine-tuning)의 막대한 비용

- **전체 파인튜닝이란?**: 사전 학습된 모델의 거대한 가중치 행렬 `W`가 있을 때, 새로운 데이터에 맞게 이 `W`의 모든 값을 조금씩 수정하여 새로운 가중치 `W' = W + ΔW`를 만드는 과정.
- **문제점**: 수천억 개에 달하는 LLM의 모든 파라미터(`ΔW`)를 학습시키려면 엄청난 양의 GPU 메모리와 학습 시간이 필요. 또한, 새로운 과제 하나마다 수백 GB에 달하는 모델 전체를 새로 저장해야 하는 비효율이 발생.

---

### 2. LoRA의 핵심 가설: "변화는 단순하다" (Low-Rank Hypothesis)

LoRA의 핵심은 **"LoRA: Low-Rank Adaptation of Large Language Models"** 라는 논문 제목에 모두 담겨 있음. 논문의 저자들은 다음과 같은 가설을 세웠음.

> **[논문 원문 (Abstract):](https://arxiv.org/pdf/2106.09685)**
> "We hypothesize that the change in weights during model adaptation has a low “intrinsic rank”, leading to our proposed method."

> **한국어 번역 및 해설:**
> "우리의 가설은, 모델을 (새로운 과제에) 적응시키는 동안 발생하는 가중치의 변화량은 낮은 **'내재적 계급(intrinsic rank)'**을 가질 것이라는 점이며, 이는 우리가 제안한 방법으로 이어짐."

여기서 'intrinsic rank가 낮다'는 것이 바로 "변화량 행렬 `ΔW`는 훨씬 단순한 정보만으로 표현할 수 있다"는 의미. 수학적으로 Rank는 정보의 복잡도를 의미하므로, `ΔW`가 Low-Rank라는 것은 이 행렬이 **두 개의 훨씬 작고 얇은 행렬의 곱으로 표현될 수 있음**을 시사.

---

### 3. LoRA의 동작 원리

LoRA는 거대한 `ΔW`를 직접 학습하는 대신, `ΔW`를 근사하는 **두 개의 작은 행렬 `A`와 `B`**를 도입하며, 이들이 바로 **Low-Rank Decomposition Matrices** .

- **`ΔW ≈ B * A`**

#### 학습 시의 병렬 구조
> "학습시의 병렬 구조는 무슨의미를 지니는가?"
![lora](<../public/assets/lora.png>)

병렬 구조가 바로 LoRA의 학습 방식. 정보가 두 갈래의 경로로 나뉘어 처리된 후 합쳐짐.

1.  **메인 경로 (Pre-trained Path)**: 입력 `x`가 원래의 거대한, 변경되지 않는(frozen) 가중치 행렬 `W`를 통과. (`h1 = W * x`)
2.  **어댑터 경로 (LoRA Path)**: 동일한 입력 `x`가 두 개의 작은 LoRA 행렬 `A`와 `B`를 차례대로 통과. (`h2 = (B * A) * x`)
3.  **최종 출력**: 두 경로의 결과가 더해져 최종 출력이 됨. (`Final Output = h1 + h2`)

이 병렬 구조의 의미는, **원래 모델이 계산한 결과값에 LoRA 어댑터가 계산한 작은 보정값(correction)을 살짝 더해주는 방식**으로 동작한다는 것. 원래 모델의 강력한 성능은 그대로 활용하면서, 새로운 과제에 필요한 최소한의 정보만 효율적으로 튜닝.

#### 파라미터 수 비교 (예시)
- 가중치 행렬 `W`의 크기가 `4096 x 4096`이고, LoRA의 Rank `r`을 `8`로 설정했다고 가정.
- **전체 파인튜닝**: `4096 * 4096` = 약 **1,677만** 개의 파라미터 학습
- **LoRA**: `(4096 * 8) + (8 * 4096)` = 약 **6만 5천** 개의 파라미터만 학습 (**99.6% 감소**)

---

### 4. 학습과 '뇌'의 관점에서 본 LoRA

모델의 '뇌'는 결국 **수많은 숫자로 이루어진 가중치 행렬(Weight Matrix)의 집합**. '학습'은 정답을 더 잘 맞히는 방향으로 이 숫자들을 반복적으로 조정하여, 데이터 속 패턴과 지식을 이 행렬 안에 새기는 과정.

이 관점에서 두 파인튜닝 방식을 비유.

1. **Pre-trained Model** -> 포토샵 원본 프로그램

    - klue/bert-base와 같은 거대 언어 모델은, 수많은 기능이 담긴 매우 무겁고 복잡한 소프트웨어인 포토샵과 비슷.
    - 그 자체로 이미지 처리(언어 이해)에 대한 엄청난 잠재력과 범용적인 능력을 갖추고 있음.

2. **Full Fine-tuning** -> 포토샵 전체 재설치

    - 상황: 포토샵에 '인물 사진 보정'이라는 새로운 기능을 추가하고 싶음.
    - 방식: 포토샵의 전체 소스 코드를 수정하고, 수십 GB에 달하는 프로그램 전체를 다시 컴파일하여 새로 설치.
    - 결과: '인물 사진 보정' 기능이 추가된 `포토샵_v2` 라는 새로운 포토샵이 탄생. 기능 하나를 추가하기 위해 프로그램 전체를 복사하고 수정했기 때문에 매우 비효율적이고, 저장 공간도 두 배로 차지.

3. **LoRA** -> 포토샵 플러그인(Plugin)

    - 상황: 똑같이 '인물 사진 보정' 기능을 추가하고 싶음.
    - 방식: 포토샵 원본 프로그램은 전혀 건드리지 않고, '인물 사진 보정' 기능만 담은 몇 MB짜리 가벼운 플러그인 파일(LoRA 어댑터)을 만듬.
    - 결과: 사용자는 포토샵 원본을 그대로 쓰다가, '인물 사진 보정'이 필요할 때만 이 플러그인을 활성화해서 사용. '풍경 사진 보정' 플러그인, '흑백 사진 필터' 플러그인 등 여러 플러그인을 만들어두고, 필요에 따라 쉽게 갈아 끼울 수 있음. 저장 공간도 거의 차지하지 않고 매우 효율적.

---

### 5. LoRA의 실용적인 장점 요약

1.  **파라미터 효율성**: 학습하는 파라미터 수를 99% 이상 줄여, 훨씬 적은 GPU 메모리와 시간으로 학습이 가능.
2.  **저장 공간 절약**: 과제마다 수백 GB의 모델 전체를 저장할 필요 없이, 몇 MB 크기의 작은 '어댑터(`A`, `B`)'만 저장하면 됨.
3.  **빠른 과제 전환**: 하나의 기본 모델을 공유하면서, 여러 과제에 대한 어댑터를 필요에 따라 쉽게 교체(plug-and-play)할 수 있음.
4.  **추론 지연 없음 (No Inference Latency)**: 학습 후 어댑터를 원래 가중치에 병합(merge)하면, 추론 시 추가 계산이 전혀 없어 속도 저하가 없음.

---

### 6. LoRA의 단점 및 고려사항

모든 기술에는 장점과 단점이 공존하듯이, LoRA도 압도적인 장점 외에 몇 가지 한계점과 고려사항이 있음.

#### 1. 성능의 한계 (Potential Performance Ceiling)
- **가설의 한계**: LoRA는 "모델의 변화량은 단순할 것이다(Low-Rank)"라는 가설 위에 성립. 만약 풀어야 할 과제가 매우 복잡하고 특이해서, 모델의 가중치를 아주 복잡하고 큰 폭으로(High-Rank) 바꿔야만 해결할 수 있다면, LoRA의 저차원 근사 방식으로는 최고의 성능에 도달하지 못할 수 있음.
- **결과**: 이런 드문 경우, 막대한 자원을 투입한 전체 파인튜닝(Full Fine-tuning)이 LoRA보다 미세하게 더 높은 성능을 보일 수 있음. 즉, LoRA를 사용하면 **효율성을 얻는 대신, 이론적으로 가능한 최고 성능을 100% 보장하지는 못할 수도 있다는 전제.**

#### 2. 추가적인 하이퍼파라미터 튜닝의 필요성
- 전체 파인튜닝이 주로 `learning_rate`에 집중한다면, LoRA는 새로운 하이퍼파라미터를 추가로 고려해야 함.
    - **`r` (rank)**: LoRA 어댑터의 크기를 결정하는 가장 중요한 값. `r`이 너무 작으면 모델이 과제를 충분히 학습하지 못하고(underfitting), 너무 크면 LoRA의 장점인 효율성이 감소하고 오히려 과적합될 수 있음.
    - **`lora_alpha`**: LoRA의 스케일링 값으로, `r`과 함께 조정하며 최적의 조합을 찾아야 함.
- **결과**: 새로운 과제에 맞는 최적의 `r`과 `alpha` 값을 찾기 위한 추가적인 실험과 튜닝 과정이 필요함.

#### 3. 만능은 아니라는 점 (Not a Silver Bullet)
- LoRA는 가장 유명하고 범용적인 PEFT(파라미터 효율적 파인튜닝) 기법이지만, 유일한 방법은 아님.
- **프롬프트 튜닝(Prompt Tuning)**, **어댑터(Adapter)**, **(IA)³** 등 다양한 다른 PEFT 기법들이 있으며, 특정 과제나 모델 구조에 따라 LoRA보다 더 효율적이거나 좋은 성능을 내는 기법이 존재할 수 있음.

> **결론적으로 LoRA의 단점은 "사용하면 안 되는 이유"라기보다는, "LoRA를 더 잘 사용하기 위해 이해하고 조절해야 할 부분".**

---

### 7. LoRA 외의 다른 PEFT 기법들

LoRA 외에도 다양한 PEFT 기법들이 있으며, 각기 다른 방식으로 파라미터 효율성을 추구.

#### 1. 어댑터 (Adapter)
- **핵심 아이디어**: 사전 학습된 모델의 레이어와 레이어 **'사이'**에, 병목(bottleneck) 구조를 가진 작은 신경망(어댑터)을 삽입하여 **이 어댑터만 학습**시키는 방식.
- **동작 방식**: 정보가 `(기존 레이어) -> (작은 어댑터) -> (기존 레이어)` 순서로 순차적으로 흐름.
- **LoRA와의 차이점**: LoRA가 병렬 구조인 것과 달리, 어댑터는 직렬 구조. 이 때문에 추론 시 어댑터 레이어를 통과하는 추가 계산 시간이 발생하여 약간의 **추론 지연(latency)이 생길 수 있음.**

#### 2. 프롬프트 튜닝 (Prompt Tuning)
- **핵심 아이디어**: 모델의 가중치는 단 하나도 건드리지 않고, 입력 문장의 **'앞'**에 붙는 가상의 프롬프트(soft prompt) 벡터를 학습시키는 방식.
- **동작 방식**: `[학습 가능한 가상 토큰들] + "번역: 나는 고양이다"` 와 같은 형태로 입력을 구성. 모델은 이 가상 토큰들을 통해 자신이 어떤 과제를 수행해야 하는지 '힌트'를 얻게 됨. 오직 이 가상 토큰들만 학습.
- **장점**: 학습 파라미터 수가 극단적으로 적어 매우 효율적.
- **단점**: 모델 내부를 직접 수정하는 것이 아니라 입력값만 바꾸므로, 복잡한 과제에서는 LoRA만큼의 성능을 내기 어려울 수 있음.

> **'학습 가능한 가상 토큰'이란?**
> 
> 모델의 진짜 입력은 단어가 아닌 '임베딩 벡터'라는 점에 착안한 아이디어. 즉, 단어를 통해 고정된 벡터를 찾는 대신, 과제 수행에 가장 최적화된 **벡터 자체를 직접 학습**하는 것. 이 벡터들은 어휘 사전에 없는 '가상'의 토큰에 해당하며, 모델의 다른 모든 가중치는 고정된 채 오직 이 '가상 토큰'의 벡터값만 학습 과정에서 업데이트 됨. 모델에게 특정 과제를 푸는 방법을 알려주는 '마법의 주문'을 벡터 공간에서 직접 찾는 것과 같음.

#### 3. (IA)³ (Infused Adapter by Inhibiting and Amplifying Activations)
- **핵심 아이디어**: 가중치를 직접 수정하는 대신, 모델 내부의 정보 흐름, 즉 **활성화(Activation) 값을 조절**하는 방식을 학습.
- **동작 방식**: 각 Transformer 블록의 특정 위치(어텐션 출력, FFNN 출력 등)에, 학습 가능한 작은 스케일링 벡터(scaling vector)를 추가. 이 벡터는 해당 위치의 정보 흐름을 **'증폭(Amplify)'**시키거나 **'억제(Inhibit)'**하는 역할을 . 모델은 어떤 정보를 더 중요하게 보고, 어떤 정보를 덜 중요하게 볼지를 학습하게 됨.
- **장점**: LoRA보다도 파라미터 효율성이 높으면서, 매우 뛰어난 성능을 보여주어 최근 각광받는 기법 중 하나.
