---
layout: post
title: "LoRA (Low-Rank Adaptation) 심층 분석: AI 모델 튜닝, 더 이상 무겁지 않게"
---

거대 언어 모델(LLM)을 내 입맛에 맞게 튜닝하고 싶은데, 어마어마한 GPU 리소스와 저장 공간 때문에 망설여 본 적 없으신가요? 새로운 과제를 시킬 때마다 수백 GB짜리 모델을 통째로 복사해야 하는 비효율에 지치셨나요?

만약 그렇다면, **LoRA(Low-Rank Adaptation)**가 바로 여러분을 위한 해결책이 될 수 있습니다. LoRA는 모델 튜닝의 패러다임을 바꾼 **PEFT(Parameter-Efficient Fine-Tuning)**, 즉 '파라미터 효율적 파인튜닝' 기법 중 가장 대표적인 주자입니다.

오늘은 LoRA가 어떻게 그런 마법 같은 효율성을 달성하는지, 그 핵심 원리를 '포토샵 플러그인' 비유와 함께 심층적으로 파헤쳐 보겠습니다.

---

### 왜 LoRA가 필요할까? 기존 파인튜닝의 한계

먼저 기존의 방식, **전체 파인튜닝(Full Fine-tuning)**의 문제점을 짚어보죠.

- **전체 파인튜닝이란?**: 사전 학습된 거대 모델(일종의 '원본 프로그램')의 수천억 개 파라미터를 전부 미세하게 조정해서, 새로운 과제에 맞는 새 버전의 모델을 만드는 방식입니다. `새로운 모델 = 원본 모델 + 모든 파라미터 수정`인 셈이죠.
- **문제점**: 이 방식은 마치 기능 하나 추가하자고 **포토샵 프로그램을 통째로 새로 컴파일하고 설치**하는 것과 같습니다. 엄청난 GPU 메모리와 학습 시간이 필요하고, 결과물인 모델 파일도 원본만큼이나 거대해서 관리하기 비효율적입니다.

---

### LoRA의 핵심 가설: "변화는 크지 않다"

LoRA의 개발자들은 아주 중요한 가설을 세웠습니다.

> "모델을 새로운 과제에 적응시킬 때, 가중치의 '변화량'은 사실 매우 단순한 정보(Low-Rank)만으로 표현할 수 있다."

이게 무슨 의미일까요? 모델의 전체 구조를 뒤흔드는 대대적인 공사 대신, **핵심적인 부분만 살짝 건드려도 충분하다**는 뜻입니다. 변화가 필요한 부분은 전체에서 아주 작은 일부이며, 그 정보량 또한 복잡하지 않다는 것이죠.

수학적으로 'Rank'는 정보의 복잡도를 의미하는데, 변화량이 'Low-Rank'라는 것은 이 변화를 **두 개의 훨씬 작고 얇은 행렬의 곱**으로 표현할 수 있음을 시사합니다.

---

### LoRA는 어떻게 동작하는가: 포토샵 플러그인처럼

LoRA는 거대한 변화량(`ΔW`)을 직접 건드리는 대신, 이 변화를 흉내 내는 **두 개의 작은 '플러그인' 행렬(`A`와 `B`)**을 만듭니다.

- **`ΔW ≈ B * A`**

#### 학습의 비밀: 병렬 처리 구조

![lora](/public/assets/lora.png)

LoRA의 학습 방식은 위 그림처럼 두 개의 경로가 병렬로 진행됩니다.

1.  **메인 경로 (원본 기능)**: 입력 데이터(`x`)가 원래 모델의 거대한, **얼지 않은(frozen)** 가중치를 그대로 통과합니다. 포토샵의 기본 기능이 동작하는 것과 같습니다.
2.  **어댑터 경로 (플러그인 기능)**: 동일한 입력 데이터(`x`)가 우리가 새로 학습시킬 작고 가벼운 LoRA 행렬 `A`와 `B`를 통과합니다. 마치 '인물 보정 플러그인'이 추가 기능을 수행하는 것과 같죠.
3.  **최종 결과**: 두 경로의 결과가 합쳐져 최종 출력이 나옵니다. 즉, **원본 모델의 강력한 성능은 그대로 유지하면서, 플러그인이 만들어낸 약간의 보정값(correction)을 더해주는 방식**입니다.

이 덕분에 우리는 수천만 개가 넘는 파라미터 대신, 단 몇만 개의 파라미터만 학습시키면 됩니다. 예를 들어, 4096x4096 크기의 행렬을 통째로 튜닝하면 약 1,677만 개의 파라미터를 학습해야 하지만, LoRA(rank=8)를 사용하면 약 6만 5천 개만 학습하면 되죠. **무려 99.6%의 파라미터가 절감**되는 효과입니다.

---

### LoRA, 그래서 뭐가 좋은데? (실용적 장점)

1.  **압도적인 효율성**: 훨씬 적은 GPU 메모리와 시간으로 모델을 튜닝할 수 있습니다.
2.  **가벼운 저장 공간**: 과제마다 수백 GB 모델 전체가 아닌, 몇 MB짜리 '플러그인(어댑터)' 파일만 저장하면 됩니다.
3.  **자유로운 교체(Plug-and-Play)**: 기본 모델 하나에 여러 과제용 LoRA 플러그인을 만들어두고, 필요에 따라 쉽게 갈아 끼울 수 있습니다.
4.  **추론 성능 저하 없음**: 학습이 끝나면 LoRA 플러그인을 원본 모델에 병합(merge)할 수 있습니다. 일단 병합되면, 추론 시에는 어떠한 추가 계산도 없으므로 속도 저하가 전혀 없습니다.

---

### LoRA 사용 전 고려할 점: 장점 뒤의 한계

물론 LoRA가 만능은 아닙니다. 몇 가지 한계와 고려사항도 존재합니다.

#### 1. 성능의 상한선
LoRA는 '변화는 단순할 것'이라는 가설 위에 있습니다. 만약 풀어야 할 과제가 매우 복잡해서 모델의 대대적인 수정이 필요한 경우, LoRA의 성능이 전체 파인튜닝보다 미세하게 낮을 수 있습니다. 효율성을 얻는 대신, 이론상 최고 성능을 약간 포기할 수도 있다는 의미입니다.

#### 2. 추가 하이퍼파라미터 튜닝
LoRA는 `r` (rank)과 `lora_alpha` 같은 추가적인 하이퍼파라미터를 가집니다. 최적의 성능을 내기 위해 이 값들을 조정하는 추가 실험이 필요할 수 있습니다.

> **결론적으로 LoRA의 단점은 "쓰지 말아야 할 이유"라기보다는, "더 잘 쓰기 위해 이해하고 조절해야 할 부분"에 가깝습니다.**

---

### LoRA 말고 다른 방법은? (다른 PEFT 기법들)

LoRA 외에도 다양한 PEFT 기법들이 각자의 방식으로 효율성을 추구합니다.

-   **어댑터(Adapter)**: 모델의 레이어 '사이'에 작은 신경망을 직렬로 삽입하여 학습합니다. 추론 시 약간의 지연이 발생할 수 있습니다.
-   **프롬프트 튜닝(Prompt Tuning)**: 모델은 그대로 두고, 입력값의 '앞'에 붙는 가상의 프롬프트 벡터만 학습하여 모델에게 과제를 안내합니다.
-   **(IA)³**: 가중치 대신 정보의 흐름(활성화 값)을 조절하는 스케일링 벡터를 학습하여, 어떤 정보를 증폭하고 억제할지 가르칩니다.

---

### 마무리하며

LoRA는 거대 언어 모델의 파인튜닝을 민주화한 혁신적인 기술입니다. 막대한 자원 없이도 누구나 자신만의 특화 모델을 만들 수 있는 길을 열어주었죠.

물론 몇 가지 트레이드오프가 존재하지만, 대부분의 경우 LoRA가 제공하는 압도적인 효율성과 실용성은 매우 매력적입니다. 이제 여러분도 LoRA를 활용하여 자신만의 AI 모델 '플러그인'을 만들어보는 것은 어떨까요?